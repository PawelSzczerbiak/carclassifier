{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we aim at training out-of-core algorithm by using database with opinions (in Polish) about cars - see db_cars folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg renault\n",
      "neg peugeot\n",
      "neg lancia\n",
      "neg mazda\n",
      "neg hyundai\n",
      "neg ssangyong\n",
      "neg skoda\n",
      "neg nissan\n",
      "neg kia\n",
      "neg mitsubishi\n",
      "neg fiat\n",
      "neg volkswagen\n",
      "neg opel\n",
      "neg citroen\n",
      "neg ford\n",
      "pos renault\n",
      "pos peugeot\n",
      "pos lancia\n",
      "pos mazda\n",
      "pos hyundai\n",
      "pos ssangyong\n",
      "pos skoda\n",
      "pos nissan\n",
      "pos kia\n",
      "pos mitsubishi\n",
      "pos fiat\n",
      "pos volkswagen\n",
      "pos opel\n",
      "pos citroen\n",
      "pos ford\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "basepath = './db_cars/data/'\n",
    "\n",
    "df = pd.DataFrame()\n",
    "labels = {'pos': 1, 'neg': 0}\n",
    "\n",
    "# Fetch all data\n",
    "\n",
    "# for l in ('pos', 'neg'):\n",
    "#     path = os.path.join(basepath, l)\n",
    "#     for file in os.listdir(path):\n",
    "#         print(l, file)\n",
    "#         for line in open(os.path.join(path, file), 'r', encoding='utf-8'):\n",
    "#             if line != '\\n': # skip empty lines\n",
    "#                 text = re.sub('\\n$', '', line) # remove end line sign\n",
    "#                 df = df.append([[text, labels[l]]], ignore_index=True)\n",
    "\n",
    "# Fetch data evenly for positive and negative opinions\n",
    "# Opinions are imbalanced: neg/pos is approx. 5%\n",
    "\n",
    "neg_numbers = {}\n",
    "\n",
    "def fetch_data(label, neg_numbers, df):\n",
    "    path = os.path.join(basepath, label)\n",
    "    for file in os.listdir(path):\n",
    "        print(label, file)\n",
    "        number = 0\n",
    "        for line in open(os.path.join(path, file), 'r', encoding='utf-8'):\n",
    "            if line != '\\n': # skip empty lines\n",
    "                number += 1\n",
    "                text = re.sub('\\n$', '', line) # remove end line sign\n",
    "                df = df.append([[text, labels[label]]], ignore_index=True)\n",
    "                if label == 'neg':\n",
    "                    neg_numbers[file] = number\n",
    "                elif neg_numbers[file] == number:\n",
    "                    break\n",
    "    return neg_numbers, df\n",
    "\n",
    "for label in ['neg', 'pos']:\n",
    "    neg_numbers, df = fetch_data(label, neg_numbers, df)\n",
    "\n",
    "df.columns = ['review', 'sentiment']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1180 1180\n"
     ]
    }
   ],
   "source": [
    "print(len(df), 2*sum(n for n in neg_numbers.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shuffling the DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(123)\n",
    "df = df.reindex(np.random.permutation(df.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional: Saving the assembled data as CSV file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('./db_cars.csv', index=False) # uncomment this !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jak najbardziej polecam</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Polecam</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Peugeot to słaby ,,Partner\" gdybym miał wybrać...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jestem zadowolony z autka</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0                            jak najbardziej polecam          1\n",
       "1                                            Polecam          1\n",
       "2  Peugeot to słaby ,,Partner\" gdybym miał wybrać...          0\n",
       "3                                                  .          1\n",
       "4                         jestem zadowolony z autka           1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./db_cars.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing - test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_content(basepath, file):\n",
    "    path = os.path.join(basepath, file)\n",
    "    with open(path, 'r', encoding='utf-8') as infile:\n",
    "        return infile.read().split()\n",
    "\n",
    "basepath = './processing_tools/'\n",
    "stop_polish = get_file_content(basepath, 'stopwords_polish')\n",
    "stop_cars = get_file_content(basepath, 'stopwords_cars')\n",
    "# stop words\n",
    "stop = stop_polish + stop_cars\n",
    "# Polish endings\n",
    "endings = get_file_content(basepath, 'endings_polish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " niena   moglibysmy oceniam na  jestem naprawde zadowolony i mimo ze juz niechcialem kupowac p d   raz kolejny nowego auta ze wzgledu na duza utrate wartosci to lancia bardzo   tys km iii osladza swiadomosc utraty  \n"
     ]
    }
   ],
   "source": [
    "example = 'nie na 8/30, moglibysmy, oceniam na 29%. Jestem,naprawdę zadowolony i mimo, \\\n",
    "że już nie   chciałem kupować :p :D po45 767 raz kolejny nowego \\\n",
    "auta ze względu:-) na;( dużą utratę wartości, \\\n",
    "to Lancia bardzo sku11tecznie 100 tys km iii osładza świadomość utraty finansowej45%. :)'\n",
    "\n",
    "polish_letters = [\n",
    "    ('ą','a'), ('ć','c'), ('ę','e'), ('ł','l'), ('ń','n'), \n",
    "    ('ó','o'), ('ś','s'), ('ź','z'), ('ż','z')]\n",
    "\n",
    "def fetch_important(text):\n",
    "    # fetch emoticons\n",
    "    emoticons = re.findall('[:;=]-?[()DPp]', text)\n",
    "    emoticons = [e.replace('-','') for e in emoticons]\n",
    "    # fetch rates (e.g. 8/10 or 100%)\n",
    "    rates = re.findall('(\\d+/\\d+|\\d+%)', text)\n",
    "    return emoticons + rates\n",
    "\n",
    "def preprocessor(text):\n",
    "    # remove non-letter characters\n",
    "    text = re.sub('\\W+', ' ', text)\n",
    "    # remove terms that contain digits\n",
    "    text = re.sub('[\\w]*\\d+[\\w]*', '', text)\n",
    "    # to lower case\n",
    "    text = text.lower()\n",
    "    # remove Polish letters\n",
    "    for (i, j) in polish_letters:\n",
    "        text = re.sub(i, j, text)\n",
    "    # join 'nie' with subsequent word\n",
    "    text = re.sub('(^|\\s)(nie)\\s+', ' nie', text)\n",
    "    return text\n",
    "\n",
    "print(preprocessor(example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_endings(word):\n",
    "    for ending in endings:\n",
    "        word = re.sub(ending+'$','', word)\n",
    "    return word\n",
    "\n",
    "def tokenizer(text):\n",
    "    # fetch important tokens (emoticons and rates)\n",
    "    important = fetch_important(text)\n",
    "    # clean text\n",
    "    processed = preprocessor(text)\n",
    "    # remove irrelevant words (one-letter, Polish, car-specific)\n",
    "    words = [w for w in processed.split() if len(w) > 1 and w not in stop]\n",
    "    # remove Polish endings\n",
    "    tokens = [remove_endings(w) for w in words]\n",
    "    return tokens + important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nie na 8/30, moglibysmy, oceniam na 29%. Jestem,naprawdę zadowolony i mimo, że już nie   chciałem kupować :p :D po45 767 raz kolejny nowego auta ze względu:-) na;( dużą utratę wartości, to Lancia bardzo sku11tecznie 100 tys km iii osładza świadomość utraty finansowej45%. :)'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['niena', 'mogli', 'oceniam', 'naprawde', 'zadowolony', 'mimo', 'juz', 'niechcialem', 'kupowac', 'kolejny', 'nowego', 'auta', 'wzgledu', 'duza', 'utrate', 'wartosci', 'lancia', 'bardzo', 'osladza', 'swiadomosc', 'utraty', ':p', ':D', ':)', ';(', ':)', '8/30', '29%', '45%']\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer(example))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Out-of-core learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stream_docs(path):\n",
    "    with open(path, 'r') as csv:\n",
    "        next(csv) # skip header\n",
    "        for line in csv:\n",
    "            text, label = line[:-3], int(line[-2])\n",
    "            yield text, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('jak najbardziej polecam', 1)\n"
     ]
    }
   ],
   "source": [
    "db_example = next(stream_docs(path='./db_cars.csv'))\n",
    "print(db_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['jak', 'najbardziej', 'polecam']\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer(db_example[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_minibatch(doc_stream, size):\n",
    "    docs, y = [], []\n",
    "    try:\n",
    "        for _ in range(size):\n",
    "            text, label = next(doc_stream)\n",
    "            docs.append(text)\n",
    "            y.append(label)\n",
    "    except StopIteration:\n",
    "        return None, None\n",
    "    return docs, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "vect = HashingVectorizer(decode_error='ignore', \n",
    "                         n_features=2**21,\n",
    "                         preprocessor=None, \n",
    "                         tokenizer=tokenizer)\n",
    "\n",
    "clf = SGDClassifier(loss='log', random_state=1, max_iter=1)\n",
    "doc_stream = stream_docs(path='./db_cars.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes = np.array([0, 1])\n",
    "for _ in range(11):\n",
    "    X_train, y_train = get_minibatch(doc_stream, size=100)\n",
    "    if not X_train:\n",
    "        break\n",
    "    X_train = vect.transform(X_train)\n",
    "    clf.partial_fit(X_train, y_train, classes=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.750\n"
     ]
    }
   ],
   "source": [
    "X_test, y_test = get_minibatch(doc_stream, size=80)\n",
    "X_test = vect.transform(X_test)\n",
    "print('Accuracy: %.3f' % clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = clf.partial_fit(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
