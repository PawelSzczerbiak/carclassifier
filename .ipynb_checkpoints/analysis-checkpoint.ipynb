{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we aim at training out-of-core algorithm by using database with opinions (in Polish) about cars - see db_cars folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg peugeot\n",
      "neg kia\n",
      "neg hyundai\n",
      "neg mazda\n",
      "neg opel\n",
      "neg lancia\n",
      "neg renault\n",
      "neg citroen\n",
      "neg volkswagen\n",
      "neg ford\n",
      "neg ssangyong\n",
      "neg skoda\n",
      "neg nissan\n",
      "neg fiat\n",
      "neg mitsubishi\n",
      "pos peugeot\n",
      "pos kia\n",
      "pos hyundai\n",
      "pos mazda\n",
      "pos opel\n",
      "pos lancia\n",
      "pos renault\n",
      "pos citroen\n",
      "pos volkswagen\n",
      "pos ford\n",
      "pos ssangyong\n",
      "pos skoda\n",
      "pos nissan\n",
      "pos fiat\n",
      "pos mitsubishi\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from sklearn.utils import resample\n",
    "\n",
    "basepath = './db_cars/data/'\n",
    "\n",
    "labels = {'pos': 1, 'neg': 0}\n",
    "\n",
    "# Opinions are imbalanced: neg/pos is approx. 6%\n",
    "# We need to fetch data evenly for positive and negative opinions\n",
    "# There are two options: \n",
    "\n",
    "# 1) Downsample majority class (positive opinions)\n",
    "\n",
    "def fetch_data_downsample():\n",
    "    df = pd.DataFrame()\n",
    "    neg_numbers = {} # numbers of negative opinions in files\n",
    "    for label in ['neg', 'pos']:\n",
    "        path = os.path.join(basepath, label)\n",
    "        for file in os.listdir(path):\n",
    "            print(label, file)\n",
    "            number = 0\n",
    "            for line in open(os.path.join(path, file), 'r', encoding='utf-8'):\n",
    "                if line != '\\n': # skip empty lines\n",
    "                    number += 1\n",
    "                    text = re.sub('\\n$', '', line) # remove end line sign\n",
    "                    df = df.append([[text, labels[label]]], ignore_index=True)\n",
    "                    if label == 'neg':\n",
    "                        neg_numbers[file] = number\n",
    "                    elif neg_numbers[file] == number:\n",
    "                        break\n",
    "    df.columns = ['review', 'sentiment']\n",
    "    return df\n",
    "\n",
    "# 2) Upsample minority class (negative opinions)\n",
    "\n",
    "def fetch_data_upsample():\n",
    "    df = pd.DataFrame()\n",
    "    for label in ['neg', 'pos']:\n",
    "        path = os.path.join(basepath, label)\n",
    "        for file in os.listdir(path):\n",
    "            print(label, file)\n",
    "            for line in open(os.path.join(path, file), 'r', encoding='utf-8'):\n",
    "                if line != '\\n': # skip empty lines\n",
    "                    text = re.sub('\\n$', '', line) # remove end line sign\n",
    "                    df = df.append([[text, labels[label]]], ignore_index=False)\n",
    "    df.columns = ['review', 'sentiment']\n",
    "    return upsample_minority(df)                \n",
    "\n",
    "def upsample_minority(df):\n",
    "    # Separate majority and minority classes\n",
    "    df_minority = df[df.sentiment==0]\n",
    "    df_majority = df[df.sentiment==1]\n",
    "\n",
    "    # Upsample minority class\n",
    "    majority_number = df['sentiment'].value_counts()[1] \n",
    "    df_minority_upsampled = resample(df_minority, \n",
    "                                     replace=True, # sample with replacement\n",
    "                                     n_samples = majority_number, # to match majority class\n",
    "                                     random_state=0)\n",
    "\n",
    "    # Combine majority class with upsampled minority class\n",
    "    return pd.concat([df_majority, df_minority_upsampled], ignore_index=True)\n",
    "\n",
    "#df = fetch_data_downsample()\n",
    "#db_path = './db_cars_downsampled.csv'\n",
    "\n",
    "df = fetch_data_upsample()\n",
    "db_path = './db_cars_upsampled.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class counts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    10156\n",
       "0    10156\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shuffling the DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(1)\n",
    "df = df.reindex(np.random.permutation(df.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional: Saving the assembled data as CSV file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df.to_csv(db_path, index=False) # uncomment this !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Auto udane, tanie w eksploatacji, bardzo trwał...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NIE POLECAM</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mialem takie autko peugeot 106 1,4D 1994 r , s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.7diesel w kombiaku wiekowy ale mnie nie zawo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dosyć głośno wewnątrz</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  Auto udane, tanie w eksploatacji, bardzo trwał...          1\n",
       "1                                        NIE POLECAM          0\n",
       "2  mialem takie autko peugeot 106 1,4D 1994 r , s...          1\n",
       "3  1.7diesel w kombiaku wiekowy ale mnie nie zawo...          1\n",
       "4                             dosyć głośno wewnątrz           0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(db_path)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing - test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_file_content(basepath, file):\n",
    "    path = os.path.join(basepath, file)\n",
    "    with open(path, 'r', encoding='utf-8') as infile:\n",
    "        return infile.read().split()\n",
    "\n",
    "basepath = './processing_tools/'\n",
    "stop_polish = get_file_content(basepath, 'stopwords_polish')\n",
    "stop_cars = get_file_content(basepath, 'stopwords_cars')\n",
    "# stop words\n",
    "stop = stop_polish + stop_cars\n",
    "# Polish endings\n",
    "endings = get_file_content(basepath, 'endings_polish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " niena   moglibysmy oceniam na  jestem naprawde zadowolony i mimo ze juz niechcialem kupowac p d   raz kolejny nowego auta ze wzgledu na duza utrate wartosci to lancia bardzo   tys km iii osladza swiadomosc utraty  \n"
     ]
    }
   ],
   "source": [
    "example = 'nie na 8/30, moglibysmy, oceniam na 29%. Jestem,naprawdę zadowolony i mimo, \\\n",
    "że już nie   chciałem kupować :p :D po45 767 raz kolejny nowego \\\n",
    "auta ze względu:-) na;( dużą utratę wartości, \\\n",
    "to Lancia bardzo sku11tecznie 100 tys km iii osładza świadomość utraty finansowej45%. :)'\n",
    "\n",
    "polish_letters = [\n",
    "    ('ą','a'), ('ć','c'), ('ę','e'), ('ł','l'), ('ń','n'), \n",
    "    ('ó','o'), ('ś','s'), ('ź','z'), ('ż','z')]\n",
    "\n",
    "def fetch_important(text):\n",
    "    # fetch emoticons\n",
    "    emoticons = re.findall('[:;=]-?[()DPp]', text)\n",
    "    emoticons = [e.replace('-','') for e in emoticons]\n",
    "    # fetch rates (e.g. 8/10 or 100%)\n",
    "    rates = re.findall('(\\d+/\\d+|\\d+%)', text)\n",
    "    return emoticons + rates\n",
    "\n",
    "def preprocessor(text):\n",
    "    # remove non-letter characters\n",
    "    text = re.sub('\\W+', ' ', text)\n",
    "    # remove terms that contain digits\n",
    "    text = re.sub('[\\w]*\\d+[\\w]*', '', text)\n",
    "    # to lower case\n",
    "    text = text.lower()\n",
    "    # remove Polish letters\n",
    "    for (i, j) in polish_letters:\n",
    "        text = re.sub(i, j, text)\n",
    "    # join 'nie' with subsequent word\n",
    "    text = re.sub('(^|\\s)(nie)\\s+', ' nie', text)\n",
    "    return text\n",
    "\n",
    "print(preprocessor(example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_endings(word):\n",
    "    for ending in endings:\n",
    "        word = re.sub(ending+'$','', word)\n",
    "    return word\n",
    "\n",
    "def tokenizer(text):\n",
    "    # fetch important tokens (emoticons and rates)\n",
    "    important = fetch_important(text)\n",
    "    # clean text\n",
    "    processed = preprocessor(text)\n",
    "    # remove irrelevant words (one-letter, Polish, car-specific)\n",
    "    words = [w for w in processed.split() if len(w) > 1 and w not in stop]\n",
    "    # remove Polish endings\n",
    "    tokens = [remove_endings(w) for w in words]\n",
    "    return tokens + important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nie na 8/30, moglibysmy, oceniam na 29%. Jestem,naprawdę zadowolony i mimo, że już nie   chciałem kupować :p :D po45 767 raz kolejny nowego auta ze względu:-) na;( dużą utratę wartości, to Lancia bardzo sku11tecznie 100 tys km iii osładza świadomość utraty finansowej45%. :)'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['niena', 'mogli', 'oceniam', 'naprawde', 'zadowolony', 'mimo', 'juz', 'niechcialem', 'kupowac', 'kolejny', 'nowego', 'auta', 'wzgledu', 'duza', 'utrate', 'wartosci', 'lancia', 'bardzo', 'osladza', 'swiadomosc', 'utraty', ':p', ':D', ':)', ';(', ':)', '8/30', '29%', '45%']\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer(example))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Out-of-core learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stream_docs(path):\n",
    "    with open(path, 'r') as csv:\n",
    "        next(csv) # skip header\n",
    "        for line in csv:\n",
    "            text, label = line[:-3], int(line[-2])\n",
    "            yield text, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('\"Auto udane, tanie w eksploatacji, bardzo trwały, tanie części zamienne\"', 1)\n"
     ]
    }
   ],
   "source": [
    "db_example = next(stream_docs(path = db_path))\n",
    "print(db_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['auto', 'udane', 'tanie', 'eksploatacji', 'bardzo', 'trwaly', 'tanie', 'czesci', 'zamienne']\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer(db_example[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_minibatch(doc_stream, size):\n",
    "    docs, y = [], []\n",
    "    try:\n",
    "        for _ in range(size):\n",
    "            text, label = next(doc_stream)\n",
    "            docs.append(text)\n",
    "            y.append(label)\n",
    "    except StopIteration:\n",
    "        return None, None\n",
    "    return docs, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "vect = HashingVectorizer(decode_error='ignore', \n",
    "                         n_features=2**21,\n",
    "                         preprocessor=None, \n",
    "                         tokenizer=tokenizer)\n",
    "\n",
    "clf = SGDClassifier(loss='log', random_state=1, max_iter=1)\n",
    "doc_stream = stream_docs(path= db_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes = np.array([0, 1])\n",
    "for _ in range(9):\n",
    "    X_train, y_train = get_minibatch(doc_stream, size=2000)\n",
    "    if not X_train:\n",
    "        break\n",
    "    X_train = vect.transform(X_train)\n",
    "    clf.partial_fit(X_train, y_train, classes=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.913\n"
     ]
    }
   ],
   "source": [
    "X_test, y_test = get_minibatch(doc_stream, size=2312)\n",
    "X_test = vect.transform(X_test)\n",
    "print('Accuracy: %.3f' % clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = clf.partial_fit(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
